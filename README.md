# ğŸ©º Scrapy + Selenium: Consulta de Medicamentos no Portal Nacional de ContrataÃ§Ãµes PÃºblicas

Este projeto Ã© uma ferramenta automatizada desenvolvida em **Python**, utilizando **Scrapy** e **Selenium**, para realizar consultas no **Portal Nacional de ContrataÃ§Ãµes PÃºblicas (PNCP)**. Ele busca informaÃ§Ãµes relacionadas a medicamentos com base em palavras-chave correspondentes ao princÃ­pio ativo de cada medicamento.

## ğŸš€ Funcionalidades

- **Consulta Automatizada:** Realiza buscas no PNCP com base em palavras-chave definidas.
- **ExtraÃ§Ã£o de Dados:** Coleta informaÃ§Ãµes relevantes das consultas.
- **Armazenamento em JSON:** Salva os resultados em um arquivo `.json`.
- **ConversÃ£o para Excel:** Um segundo script transforma o arquivo `.json` em um arquivo `.xlsx`, organizando os dados por palavra-chave.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python**
- **Scrapy**
- **Selenium**
- **Pandas**

## ğŸ“‚ Estrutura do Projeto

```
.
â”œâ”€â”€ eCorp/              # DiretÃ³rio principal do projeto
â”‚   â”œâ”€â”€ spiders/        # MÃ³dulos principais do Scrapy
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ consultabot.py
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ items.py
â”‚   â”‚   â”œâ”€â”€ middlewares.py
â”‚   â”‚   â”œâ”€â”€ pipelines.py
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚
â”‚   â”œâ”€â”€ dados_brutos.json  # Resultado bruto extraÃ­do
â”‚   â”œâ”€â”€ dados.xls          # Resultado final em Excel
â”‚   â”œâ”€â”€ process_data.py    # Script para processamento dos dados
â”‚   â”œâ”€â”€ scrapy.cfg         # Arquivo de configuraÃ§Ã£o do Scrapy
â”‚
â”œâ”€â”€ venv/              # Ambiente virtual Python
â”œâ”€â”€ requirements.txt   # DependÃªncias do projeto
â”œâ”€â”€ RPA Challenge.pdf  # DocumentaÃ§Ã£o adicional
```

## âš™ï¸ Como Executar

### 1. Clone o RepositÃ³rio
```bash
git clone https://github.com/CauanNeves/RPA-Challenge.git
cd RPA-Challenge
```

### 2. Ative o Ambiente Virtual
```bash
source venv/bin/activate  # No Linux/Mac
venv\Scripts\activate    # No Windows
```

### 3. Execute o Crawler
```bash
cd eCorp
scrapy crawl consultabot -o dados_brutos.json
```

Isso irÃ¡ gerar um arquivo `dados_brutos.json`.

### 4. Processe os Dados
```bash
python process_data.py
```

O arquivo `dados.xls` serÃ¡ gerado na pasta raiz.

## âœ… ContribuiÃ§Ãµes

Sinta-se Ã  vontade para contribuir com melhorias, abrir **issues** ou enviar **pull requests**.

---

âœ¨ *Desenvolvido por Cauan Neves utilizando Scrapy, Selenium e dedicaÃ§Ã£o!* ğŸš€
